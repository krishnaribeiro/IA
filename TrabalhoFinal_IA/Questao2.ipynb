{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "friJ2bVxHNT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5caef9-1802-459a-d9dc-6dccacf9368a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: LTNtorch in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from LTNtorch) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from LTNtorch) (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->LTNtorch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->LTNtorch) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->LTNtorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->LTNtorch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install LTNtorch\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ltn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_100 = '/content/trains_data_100 - trains-data.csv'\n",
        "data_10  = '/content/trains-data.csv'"
      ],
      "metadata": {
        "id": "2tWFKlLxKPK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 2\n",
        "Implemente uma solução em LTNTorch para o problema dos trens\n",
        "considerando os 11 predicados."
      ],
      "metadata": {
        "id": "hJd_ABSkJrlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preciso criar, em LTNTorch, um modelo que aprenda os 11 predicados a seguir:\n",
        "1. num_cars(t, nc), em que t ∊ [1..10] e nc ∊ [3..5].\n",
        "2. num_loads(t, nl) em que t ∊ [1..10] e nl ∊ [1..4].\n",
        "3. num_wheels(t, c, w) em que t ∊ [1..10] e c ∊ [1..4] e w ∊ [2..3].\n",
        "4. length(t, c, l) em que t ∊ [1..10] e c ∊ [1..4] e l ∊ [-1..1] (-1 denota curto e 1 longo)\n",
        "5. shape(t, c, s) em que t ∊ [1..10] e c ∊ [1..4] e s ∊ [1..10] (um número para\n",
        "cada forma).\n",
        "6. num_cars_loads(t, c, ncl) em que t ∊ [1..10] e c ∊ [1..4] e ncl ∊ [0..3].\n",
        "7. load_shape(t, c, ls) em que t ∊ [1..10] e c ∊ [1..4] e ls ∊ [1..4].\n",
        "8. next_crc(t, c, x) em que t ∊ [1..10] e c ∊ [1..4] e x ∊ [-1..1], em que o vagão c do trem t tem um vagão adjacente com cargas em círculo.\n",
        "9. next_hex(t, c, x) em que t ∊ [1..10] e c ∊ [1..4] e x ∊ [-1..1], em que o vagão c do trem t tem um vagão adjacente com cargas em hexágono.\n",
        "10. next_rec(t, c, x) em que t ∊ [1..10] e c ∊ [1..4] e x ∊ [-1..1], em que o vagão c do trem t tem um vagão adjacente com cargas em retângulo.\n",
        "11. next_tri(t, c, x) em que t ∊ [1..10] e c ∊ [1..4] e x ∊ [-1..1], em que o vagão c do trem t tem um vagão adjacente com cargas em triângulo"
      ],
      "metadata": {
        "id": "y5tzAiCoJrd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df10  = pd.read_csv(data_10)\n",
        "df100 = pd.read_csv(data_100)"
      ],
      "metadata": {
        "id": "tF-90G0iXNdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df10.info()"
      ],
      "metadata": {
        "id": "qIbDcfL8XXYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f008093-7576-4587-8d00-f46a2d00b989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 33 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Number_of_cars               10 non-null     int64  \n",
            " 1   Number_of_different_loads    10 non-null     int64  \n",
            " 2   num_wheels1                  10 non-null     int64  \n",
            " 3   length1                      10 non-null     object \n",
            " 4   shape1                       10 non-null     object \n",
            " 5   num_loads1                   10 non-null     int64  \n",
            " 6   load_shape1                  10 non-null     object \n",
            " 7   num_wheels2                  10 non-null     int64  \n",
            " 8   length2                      10 non-null     object \n",
            " 9   shape2                       10 non-null     object \n",
            " 10  num_loads2                   10 non-null     int64  \n",
            " 11  load_shape2                  10 non-null     object \n",
            " 12  num_wheels3                  7 non-null      float64\n",
            " 13  length3                      7 non-null      object \n",
            " 14  shape3                       7 non-null      object \n",
            " 15  num_loads3                   7 non-null      float64\n",
            " 16  load_shape3                  6 non-null      object \n",
            " 17  num_wheels4                  3 non-null      float64\n",
            " 18  length4                      3 non-null      object \n",
            " 19  shape4                       3 non-null      object \n",
            " 20  num_loads4                   3 non-null      float64\n",
            " 21  load_shape4                  3 non-null      object \n",
            " 22  Rectangle_next_to_rectangle  10 non-null     int64  \n",
            " 23  Rectangle_next_to_triangle   10 non-null     int64  \n",
            " 24  Rectangle_next_to_hexagon    10 non-null     int64  \n",
            " 25  Rectangle_next_to_circle     10 non-null     int64  \n",
            " 26  Triangle_next_to_triangle    10 non-null     int64  \n",
            " 27  Triangle_next_to_hexagon     10 non-null     int64  \n",
            " 28  Triangle_next_to_circle      10 non-null     int64  \n",
            " 29  Hexagon_next_to_hexagon      10 non-null     int64  \n",
            " 30  Hexagon_next_to_circle       10 non-null     int64  \n",
            " 31  Circle_next_to_circle        10 non-null     int64  \n",
            " 32  Class_attribute              10 non-null     object \n",
            "dtypes: float64(4), int64(16), object(13)\n",
            "memory usage: 2.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df100.info()"
      ],
      "metadata": {
        "id": "-ubV9PnoXlh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fbe670-fad4-4537-c93f-995f91afb051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 33 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Number_of_cars               100 non-null    int64  \n",
            " 1   Number_of_different_loads    100 non-null    int64  \n",
            " 2   num_wheels1                  100 non-null    int64  \n",
            " 3   length1                      100 non-null    object \n",
            " 4   shape1                       100 non-null    object \n",
            " 5   num_loads1                   100 non-null    int64  \n",
            " 6   load_shape1                  98 non-null     object \n",
            " 7   num_wheels2                  100 non-null    int64  \n",
            " 8   length2                      100 non-null    object \n",
            " 9   shape2                       100 non-null    object \n",
            " 10  num_loads2                   97 non-null     float64\n",
            " 11  load_shape2                  97 non-null     object \n",
            " 12  num_wheels3                  75 non-null     float64\n",
            " 13  length3                      74 non-null     object \n",
            " 14  shape3                       74 non-null     object \n",
            " 15  num_loads3                   73 non-null     float64\n",
            " 16  load_shape3                  72 non-null     object \n",
            " 17  num_wheels4                  37 non-null     float64\n",
            " 18  length4                      37 non-null     object \n",
            " 19  shape4                       37 non-null     object \n",
            " 20  num_loads4                   37 non-null     float64\n",
            " 21  load_shape4                  37 non-null     object \n",
            " 22  Rectangle_next_to_rectangle  100 non-null    int64  \n",
            " 23  Rectangle_next_to_triangle   100 non-null    int64  \n",
            " 24  Rectangle_next_to_hexagon    100 non-null    int64  \n",
            " 25  Rectangle_next_to_circle     100 non-null    int64  \n",
            " 26  Triangle_next_to_triangle    100 non-null    int64  \n",
            " 27  Triangle_next_to_hexagon     100 non-null    int64  \n",
            " 28  Triangle_next_to_circle      100 non-null    int64  \n",
            " 29  Hexagon_next_to_hexagon      100 non-null    int64  \n",
            " 30  Hexagon_next_to_circle       100 non-null    int64  \n",
            " 31  Circle_next_to_circle        100 non-null    int64  \n",
            " 32  Class_attribute              100 non-null    object \n",
            "dtypes: float64(5), int64(15), object(13)\n",
            "memory usage: 25.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nan treatment\n",
        "def input_nan(df, columns, value):\n",
        "  for col in columns:\n",
        "    df[col] = df[col].fillna(value)\n",
        "  return df\n",
        "\n",
        "categorical_columns = [[f'length{i}', f'shape{i}', f'load_shape{i}'] for i in range(1, 5)]\n",
        "categorical_columns = [item for sublist in categorical_columns for item in sublist]\n",
        "input_value = \"\"\n",
        "df10 = input_nan(df10, categorical_columns, input_value)\n",
        "df100 = input_nan(df100, categorical_columns, input_value)"
      ],
      "metadata": {
        "id": "5oxlJtVReOJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = [[f'num_wheels{i}', f'num_loads{i}'] for i in range(1, 5)]\n",
        "numerical_columns = [item for sublist in numerical_columns for item in sublist]\n",
        "input_value = 0\n",
        "df10 = input_nan(df10, numerical_columns, input_value)\n",
        "df100 = input_nan(df100, numerical_columns, input_value)"
      ],
      "metadata": {
        "id": "r3SBDl-EgM3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df10.info()"
      ],
      "metadata": {
        "id": "hdQkdU0Og9Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acec855-6c69-4f59-98dc-7a69523f10d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 33 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Number_of_cars               10 non-null     int64  \n",
            " 1   Number_of_different_loads    10 non-null     int64  \n",
            " 2   num_wheels1                  10 non-null     int64  \n",
            " 3   length1                      10 non-null     object \n",
            " 4   shape1                       10 non-null     object \n",
            " 5   num_loads1                   10 non-null     int64  \n",
            " 6   load_shape1                  10 non-null     object \n",
            " 7   num_wheels2                  10 non-null     int64  \n",
            " 8   length2                      10 non-null     object \n",
            " 9   shape2                       10 non-null     object \n",
            " 10  num_loads2                   10 non-null     int64  \n",
            " 11  load_shape2                  10 non-null     object \n",
            " 12  num_wheels3                  10 non-null     float64\n",
            " 13  length3                      10 non-null     object \n",
            " 14  shape3                       10 non-null     object \n",
            " 15  num_loads3                   10 non-null     float64\n",
            " 16  load_shape3                  10 non-null     object \n",
            " 17  num_wheels4                  10 non-null     float64\n",
            " 18  length4                      10 non-null     object \n",
            " 19  shape4                       10 non-null     object \n",
            " 20  num_loads4                   10 non-null     float64\n",
            " 21  load_shape4                  10 non-null     object \n",
            " 22  Rectangle_next_to_rectangle  10 non-null     int64  \n",
            " 23  Rectangle_next_to_triangle   10 non-null     int64  \n",
            " 24  Rectangle_next_to_hexagon    10 non-null     int64  \n",
            " 25  Rectangle_next_to_circle     10 non-null     int64  \n",
            " 26  Triangle_next_to_triangle    10 non-null     int64  \n",
            " 27  Triangle_next_to_hexagon     10 non-null     int64  \n",
            " 28  Triangle_next_to_circle      10 non-null     int64  \n",
            " 29  Hexagon_next_to_hexagon      10 non-null     int64  \n",
            " 30  Hexagon_next_to_circle       10 non-null     int64  \n",
            " 31  Circle_next_to_circle        10 non-null     int64  \n",
            " 32  Class_attribute              10 non-null     object \n",
            "dtypes: float64(4), int64(16), object(13)\n",
            "memory usage: 2.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df100.info()"
      ],
      "metadata": {
        "id": "yf8iYEpjg_mS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6bfc19-4355-484a-8524-257cf78adb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 33 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Number_of_cars               100 non-null    int64  \n",
            " 1   Number_of_different_loads    100 non-null    int64  \n",
            " 2   num_wheels1                  100 non-null    int64  \n",
            " 3   length1                      100 non-null    object \n",
            " 4   shape1                       100 non-null    object \n",
            " 5   num_loads1                   100 non-null    int64  \n",
            " 6   load_shape1                  100 non-null    object \n",
            " 7   num_wheels2                  100 non-null    int64  \n",
            " 8   length2                      100 non-null    object \n",
            " 9   shape2                       100 non-null    object \n",
            " 10  num_loads2                   100 non-null    float64\n",
            " 11  load_shape2                  100 non-null    object \n",
            " 12  num_wheels3                  100 non-null    float64\n",
            " 13  length3                      100 non-null    object \n",
            " 14  shape3                       100 non-null    object \n",
            " 15  num_loads3                   100 non-null    float64\n",
            " 16  load_shape3                  100 non-null    object \n",
            " 17  num_wheels4                  100 non-null    float64\n",
            " 18  length4                      100 non-null    object \n",
            " 19  shape4                       100 non-null    object \n",
            " 20  num_loads4                   100 non-null    float64\n",
            " 21  load_shape4                  100 non-null    object \n",
            " 22  Rectangle_next_to_rectangle  100 non-null    int64  \n",
            " 23  Rectangle_next_to_triangle   100 non-null    int64  \n",
            " 24  Rectangle_next_to_hexagon    100 non-null    int64  \n",
            " 25  Rectangle_next_to_circle     100 non-null    int64  \n",
            " 26  Triangle_next_to_triangle    100 non-null    int64  \n",
            " 27  Triangle_next_to_hexagon     100 non-null    int64  \n",
            " 28  Triangle_next_to_circle      100 non-null    int64  \n",
            " 29  Hexagon_next_to_hexagon      100 non-null    int64  \n",
            " 30  Hexagon_next_to_circle       100 non-null    int64  \n",
            " 31  Circle_next_to_circle        100 non-null    int64  \n",
            " 32  Class_attribute              100 non-null    object \n",
            "dtypes: float64(5), int64(15), object(13)\n",
            "memory usage: 25.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df100.load_shape1.unique(), df100.load_shape2.unique(), df100.load_shape3.unique(), df100.load_shape4.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmqi0JC1fO_7",
        "outputId": "c51f04f1-d049-4340-bc17-3dff2bc0cafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['rectanglod(short)', 'circlelod', 'rectanglod(medium)',\n",
              "        'rectanglod(long)', 'trianglod', 'invtrianglod', 'hexaglod', '',\n",
              "        'upsidedowntri'], dtype=object),\n",
              " array(['trianglod', 'rectanglod(medium)', 'rectanglod(short)',\n",
              "        'circlelod', 'rectanglod(long)', 'diamondlod', 'invtrianglod',\n",
              "        'hexaglod', '', 'rectanglod'], dtype=object),\n",
              " array(['rectanglod(long)', 'circlelod', 'trianglod', 'rectanglod(medium)',\n",
              "        '', 'rectanglod(short)', 'invtrianglod', 'hexaglod', 'diamondlod'],\n",
              "       dtype=object),\n",
              " array(['', 'circlelod', 'trianglod', 'rectanglod(medium)',\n",
              "        'rectanglod(long)', 'diamondlod', 'rectanglod(short)'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "\n",
        "def transform_dataframe(df):\n",
        "    # List to hold the new rows\n",
        "    transformed_rows = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        train_number = idx\n",
        "        num_cars = row[\"Number_of_cars\"]\n",
        "        num_loads = row[\"Number_of_different_loads\"]\n",
        "        direction = row[\"Class_attribute\"]\n",
        "        # Iterate through each car in the train\n",
        "        for i in range(1, num_cars): # num_cars counts the train head itself, which is not used for any features.\n",
        "            car_number = i\n",
        "            num_wheels = row[f\"num_wheels{i}\"]\n",
        "            length = row[f\"length{i}\"]\n",
        "            shape = row[f\"shape{i}\"]\n",
        "            num_loads_i = row[f\"num_loads{i}\"]\n",
        "            load_shape = row[f\"load_shape{i}\"]\n",
        "\n",
        "            # Determine the next shape values based on current shape\n",
        "            match shape:\n",
        "              case _ if \"circle\" in shape:\n",
        "                  next_crc = row[\"Circle_next_to_circle\"]\n",
        "                  next_hex = 0\n",
        "                  next_rec = 0\n",
        "                  next_tri = 0\n",
        "              case _ if \"rect\" in shape:\n",
        "                  next_crc = row[\"Rectangle_next_to_circle\"]\n",
        "                  next_hex = row[\"Rectangle_next_to_hexagon\"]\n",
        "                  next_rec = row[\"Rectangle_next_to_rectangle\"]\n",
        "                  next_tri = row[\"Rectangle_next_to_triangle\"]\n",
        "              case _ if \"tri\" in shape:\n",
        "                   next_crc = row[\"Triangle_next_to_circle\"]\n",
        "                   next_hex = row[\"Triangle_next_to_hexagon\"]\n",
        "                   next_rec = 0\n",
        "                   next_tri = row[\"Triangle_next_to_triangle\"]\n",
        "              case _ if \"hex\" in shape:\n",
        "                  next_crc = row[\"Hexagon_next_to_circle\"]\n",
        "                  next_hex = row[\"Hexagon_next_to_hexagon\"]\n",
        "                  next_rec = 0\n",
        "                  next_tri = 0\n",
        "              case _:\n",
        "                  next_crc = 0\n",
        "                  next_hex = 0\n",
        "                  next_rec = 0\n",
        "                  next_tri = 0\n",
        "\n",
        "            # Append the new row\n",
        "            transformed_rows.append({\n",
        "                \"train_number\": train_number,\n",
        "                \"num_cars\": num_cars,\n",
        "                \"num_loads\": num_loads,\n",
        "                \"num_wheels\": num_wheels,\n",
        "                \"car_number\": car_number,\n",
        "                \"length\": length,\n",
        "                \"shape\": shape,\n",
        "                \"num_cars_loads\": num_loads_i,\n",
        "                \"load_shape\": load_shape,\n",
        "                \"next_crc\": next_crc,\n",
        "                \"next_hex\": next_hex,\n",
        "                \"next_rec\": next_rec,\n",
        "                \"next_tri\": next_tri,\n",
        "                \"direction\": direction\n",
        "            })\n",
        "\n",
        "    # Create a new DataFrame from the transformed rows\n",
        "    transformed_df = pd.DataFrame(transformed_rows)\n",
        "    return transformed_df\n",
        "\n",
        "# Example usage\n",
        "transformed_df = transform_dataframe(df100)\n",
        "transformed_df_10 = transform_dataframe(df10)"
      ],
      "metadata": {
        "id": "lfUWggdcS8AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ltn\n",
        "\n",
        "# we define the constants\n",
        "l_W = ltn.Constant(torch.tensor([1, 0]))\n",
        "l_E = ltn.Constant(torch.tensor([0, 1]))\n",
        "\n",
        "# we define predicate P\n",
        "class MLP(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    This model returns the logits for the classes given an input example. It does not compute the softmax, so the output\n",
        "    are not normalized.\n",
        "    This is done to separate the accuracy computation from the satisfaction level computation. Go through the example\n",
        "    to understand it.\n",
        "    \"\"\"\n",
        "    def __init__(self, layer_sizes=(16, 64, 32, 8, 2)):\n",
        "        super(MLP, self).__init__()\n",
        "        self.elu = torch.nn.ELU()\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
        "                                                  for i in range(1, len(layer_sizes))])\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Method which defines the forward phase of the neural network for our multi class classification task.\n",
        "        In particular, it returns the logits for the classes given an input example.\n",
        "\n",
        "        :param x: the features of the example\n",
        "        :param training: whether the network is in training mode (dropout applied) or validation mode (dropout not applied)\n",
        "        :return: logits for example x\n",
        "        \"\"\"\n",
        "        for layer in self.linear_layers[:-1]:\n",
        "            x = self.elu(layer(x))\n",
        "            if training:\n",
        "                x = self.dropout(x)\n",
        "        logits = self.linear_layers[-1](x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class EastModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
        "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
        "    while this model returns the probabilities given the logits model.\n",
        "\n",
        "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
        "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
        "    to the given class l.\n",
        "    \"\"\"\n",
        "    def __init__(self, logits_model_map, indexer):\n",
        "        super(EastModel, self).__init__()\n",
        "        self.logits_model_map = logits_model_map\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "        self.intermediate_logits = {}\n",
        "\n",
        "        self.elu = torch.nn.ELU()\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "        self.aggregatorNN = torch.nn.ModuleList([torch.nn.Linear(22, 12), torch.nn.Linear(12, 2)])\n",
        "        self.model_indexing = indexer\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        # print(x.shape)\n",
        "        for pred in self.model_indexing.keys():\n",
        "          self.intermediate_logits[pred] = self.logits_model_map[pred](x[:, self.model_indexing[pred]], training=training)\n",
        "\n",
        "        # for i in self.intermediate_logits.keys():\n",
        "        #   print(i, self.intermediate_logits[i].shape)\n",
        "\n",
        "        logits = torch.cat(list([self.intermediate_logits[key] for key in self.intermediate_logits.keys()]), dim=1) #probability to go west\n",
        "        # I want to create a MLP layer to converge the logits from each predicate into a final one.\n",
        "        # print(\"Logits shape\", logits.shape)\n",
        "        for layer in self.aggregatorNN[:-1]:\n",
        "            logits = self.elu(layer(logits))\n",
        "            if training:\n",
        "                logits = self.dropout(logits)\n",
        "        logits = self.aggregatorNN[-1](logits)\n",
        "        return logits\n",
        "class LogitsToPredicate(torch.nn.Module):\n",
        "    def __init__(self, logits_model):\n",
        "        super(LogitsToPredicate, self).__init__()\n",
        "        self.logits_model = logits_model\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x, l, training=False):\n",
        "        logits = self.logits_model(x, training=training)\n",
        "        probs = self.softmax(logits)\n",
        "        out = torch.sum(probs * l, dim=1)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# we define the connectives, quantifiers, and the SatAgg\n",
        "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
        "SatAgg = ltn.fuzzy_ops.SatAgg()"
      ],
      "metadata": {
        "id": "yDXOHqW0J8Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define metric functions\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "class DataLoader(object):\n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 batch_size=1,\n",
        "                 shuffle=True):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
        "\n",
        "    def __iter__(self):\n",
        "        class_0_idx = np.where(self.labels == 0)[0]\n",
        "        class_1_idx = np.where(self.labels == 1)[0]\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(class_0_idx)\n",
        "            np.random.shuffle(class_1_idx)\n",
        "\n",
        "        n = min(len(class_0_idx), len(class_1_idx))\n",
        "        batch_half_size = self.batch_size // 2\n",
        "\n",
        "        for i in range(0, n, batch_half_size):\n",
        "            end_idx = min(i + batch_half_size, n)\n",
        "            idx0 = class_0_idx[i:end_idx]\n",
        "            idx1 = class_1_idx[i:end_idx]\n",
        "\n",
        "            batch_idx = np.concatenate((idx0, idx1))\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(batch_idx)\n",
        "            selected_data = self.data.iloc[batch_idx]\n",
        "            selected_labels = self.labels.iloc[batch_idx]\n",
        "\n",
        "            base_columns = ['train_number', 'num_cars']\n",
        "\n",
        "            length_columns = [col for col in selected_data.columns if col.startswith('length_')]\n",
        "            shape_columns = [col for col in selected_data.columns if col.startswith('shape_')]\n",
        "            load_shape_columns = [col for col in selected_data.columns if col.startswith('load_shape_')]\n",
        "\n",
        "            inputs = []\n",
        "            inputs.append(selected_data[['train_number','num_cars']].values)\n",
        "            inputs.append(selected_data[['train_number','num_loads']].values)\n",
        "            inputs.append(selected_data[['train_number', 'car_number', 'num_wheels']].values)\n",
        "            inputs.append(selected_data[base_columns + length_columns].values)\n",
        "            inputs.append(selected_data[base_columns + shape_columns].values)\n",
        "            inputs.append(selected_data[['train_number', 'car_number', 'num_cars_loads']].values)\n",
        "            inputs.append(selected_data[base_columns + load_shape_columns].values)\n",
        "            inputs.append(selected_data[['train_number', 'car_number', 'next_crc']].values)\n",
        "            inputs.append(selected_data[['train_number', 'car_number', 'next_hex']].values)\n",
        "            inputs.append(selected_data[['train_number', 'car_number', 'next_rec']].values)\n",
        "            inputs.append(selected_data[['train_number', 'car_number', 'next_tri']].values)\n",
        "            stack_inputs = np.hstack(inputs)\n",
        "            torch_inputs = torch.tensor(stack_inputs, dtype=torch.float32)\n",
        "            selected_labels = torch.tensor(selected_labels.values, dtype=torch.float32)\n",
        "            yield torch_inputs, selected_labels\n",
        "\n",
        "\n",
        "def compute_sat_level(loader):\n",
        "    mean_sat = 0\n",
        "    for data, labels in loader:\n",
        "        x_W = ltn.Variable(\"x_W\", data[labels == 0])\n",
        "        x_E = ltn.Variable(\"x_E\", data[labels == 1])\n",
        "        mean_sat += SatAgg(\n",
        "            Forall(x_W, P(x_W, l_W)),\n",
        "            Forall(x_E, P(x_E, l_E)),\n",
        "        )\n",
        "    mean_sat /= len(loader)\n",
        "    return mean_sat"
      ],
      "metadata": {
        "id": "pnKUFZkeJ8nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Letra A\n",
        "Teste com os 10 trens do livro e compare o resultado com o o gerado pelo\n",
        "codigo fornecido, Table 2: Resultados obtidos - Questão 2"
      ],
      "metadata": {
        "id": "yNi5TUW7J_TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
        "\n",
        "categorical_columns = ['shape', 'length', 'load_shape']\n",
        "numerical_columns = ['train_number', 'num_cars', 'num_loads', 'num_wheels', 'car_number', 'num_cars_loads']\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "encoded_categorical = encoder.fit_transform(transformed_df_10[categorical_columns])\n",
        "encoded_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_numerical = scaler.fit_transform(transformed_df_10[numerical_columns])\n",
        "scaled_df = pd.DataFrame(scaled_numerical, columns=numerical_columns)\n",
        "\n",
        "df_processed = pd.concat([transformed_df_10.drop(columns=categorical_columns + numerical_columns), scaled_df, encoded_df], axis=1)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_processed['direction'] = label_encoder.fit_transform(df_processed['direction'])\n",
        "\n",
        "X = df_processed.drop(columns=['direction'])\n",
        "y = df_processed['direction']\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "train_idx, test_idx = next(gss.split(X, y, groups=transformed_df_10['train_number']))\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "train_loader = DataLoader(X_train, y_train, 64, shuffle=True)\n",
        "test_loader = DataLoader(X_test, y_test, 64, shuffle=False)"
      ],
      "metadata": {
        "id": "ci57fCquKBJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1402158a-bf56-480f-d528-ed0226003dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_map = {\n",
        "    \"num_cars\": MLP(layer_sizes=(2, 8, 2)),\n",
        "    \"num_loads\": MLP(layer_sizes=(2, 8, 2)),\n",
        "    \"num_wheels\": MLP(layer_sizes=(3, 8, 2)),\n",
        "    \"length\": MLP(layer_sizes=(3, 8, 2)),\n",
        "    \"shape\": MLP(layer_sizes=(10, 16, 2)),\n",
        "    \"num_cars_loads\": MLP(layer_sizes=(3, 8, 2)),\n",
        "    \"load_shape\": MLP(layer_sizes=(6, 16, 2)),\n",
        "    \"next_crc\": MLP(layer_sizes=(3, 8, 2)),\n",
        "    \"next_hex\": MLP(layer_sizes=(3, 8, 2)),\n",
        "    \"next_rec\": MLP(layer_sizes=(3, 8, 2)),\n",
        "    \"next_tri\": MLP(layer_sizes=(3, 8, 2))\n",
        "}\n",
        "indexer = {\n",
        "            \"num_cars\": list(range(0, 2)),\n",
        "            \"num_loads\": list(range(2, 4)),\n",
        "            \"num_wheels\": list(range(4, 7)),\n",
        "            \"length\": list(range(7, 10)),\n",
        "            \"shape\": list(range(10, 20)),\n",
        "            \"num_cars_loads\": list(range(20, 23)),\n",
        "            \"load_shape\": list(range(23, 29)),\n",
        "            \"next_crc\": list(range(29, 32)),\n",
        "            \"next_hex\": list(range(32, 35)),\n",
        "            \"next_rec\": list(range(35, 38)),\n",
        "            \"next_tri\": list(range(38, 41))\n",
        "        }\n",
        "\n",
        "east = EastModel(pred_map, indexer)\n",
        "P = ltn.Predicate(LogitsToPredicate(east))"
      ],
      "metadata": {
        "id": "NF3I-YxyQPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training\n",
        "optimizer = torch.optim.Adam(P.parameters(), lr=0.0001)\n",
        "def compute_accuracy(loader):\n",
        "    mean_accuracy = 0.0\n",
        "    for data, labels in loader:\n",
        "        predictions = east(data).detach().numpy()\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        mean_accuracy += accuracy_score(labels, predictions)\n",
        "\n",
        "    return mean_accuracy / len(loader)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x_W = ltn.Variable(\"x_W\", data[labels == 0]) # West samples\n",
        "        x_E = ltn.Variable(\"x_E\", data[labels == 1]) # East samples\n",
        "        sat_agg = SatAgg(\n",
        "            Forall(x_W, P(x_W, l_W, training=True)),\n",
        "            Forall(x_E, P(x_E, l_E, training=True)),\n",
        "        )\n",
        "        loss = 1. - sat_agg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # we print metrics every 20 epochs of training\n",
        "    if epoch % 20 == 0:\n",
        "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
        "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
        "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v25Tn_9ONSR",
        "outputId": "430608f6-0564-464d-d93b-68d1062dc877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch 0 | loss 0.5049 | Train Sat 0.499 | Test Sat 0.499 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 20 | loss 0.4990 | Train Sat 0.497 | Test Sat 0.500 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 40 | loss 0.4893 | Train Sat 0.499 | Test Sat 0.500 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 60 | loss 0.5072 | Train Sat 0.500 | Test Sat 0.501 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 80 | loss 0.5019 | Train Sat 0.502 | Test Sat 0.502 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 100 | loss 0.5013 | Train Sat 0.503 | Test Sat 0.502 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 120 | loss 0.5012 | Train Sat 0.502 | Test Sat 0.503 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 140 | loss 0.4891 | Train Sat 0.508 | Test Sat 0.503 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 160 | loss 0.5073 | Train Sat 0.504 | Test Sat 0.504 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 180 | loss 0.4841 | Train Sat 0.508 | Test Sat 0.504 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 200 | loss 0.4986 | Train Sat 0.507 | Test Sat 0.505 | Train Acc 0.556 | Test Acc 0.500\n",
            " epoch 220 | loss 0.4929 | Train Sat 0.509 | Test Sat 0.505 | Train Acc 0.556 | Test Acc 0.667\n",
            " epoch 240 | loss 0.4974 | Train Sat 0.509 | Test Sat 0.506 | Train Acc 0.667 | Test Acc 0.667\n",
            " epoch 260 | loss 0.4915 | Train Sat 0.510 | Test Sat 0.506 | Train Acc 0.667 | Test Acc 0.667\n",
            " epoch 280 | loss 0.4904 | Train Sat 0.511 | Test Sat 0.507 | Train Acc 0.722 | Test Acc 0.667\n",
            " epoch 300 | loss 0.4961 | Train Sat 0.514 | Test Sat 0.507 | Train Acc 0.722 | Test Acc 0.667\n",
            " epoch 320 | loss 0.4886 | Train Sat 0.510 | Test Sat 0.508 | Train Acc 0.722 | Test Acc 0.667\n",
            " epoch 340 | loss 0.4937 | Train Sat 0.513 | Test Sat 0.508 | Train Acc 0.778 | Test Acc 0.667\n",
            " epoch 360 | loss 0.4926 | Train Sat 0.514 | Test Sat 0.509 | Train Acc 0.778 | Test Acc 0.667\n",
            " epoch 380 | loss 0.4864 | Train Sat 0.514 | Test Sat 0.509 | Train Acc 0.778 | Test Acc 0.667\n",
            " epoch 400 | loss 0.5010 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.778 | Test Acc 0.667\n",
            " epoch 420 | loss 0.5001 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.889 | Test Acc 0.667\n",
            " epoch 440 | loss 0.4756 | Train Sat 0.517 | Test Sat 0.510 | Train Acc 0.833 | Test Acc 0.667\n",
            " epoch 460 | loss 0.4873 | Train Sat 0.519 | Test Sat 0.511 | Train Acc 0.833 | Test Acc 0.667\n",
            " epoch 480 | loss 0.4936 | Train Sat 0.518 | Test Sat 0.511 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 500 | loss 0.4707 | Train Sat 0.516 | Test Sat 0.512 | Train Acc 0.833 | Test Acc 0.833\n",
            " epoch 520 | loss 0.4937 | Train Sat 0.517 | Test Sat 0.512 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 540 | loss 0.4849 | Train Sat 0.519 | Test Sat 0.513 | Train Acc 0.833 | Test Acc 0.833\n",
            " epoch 560 | loss 0.4777 | Train Sat 0.520 | Test Sat 0.513 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 580 | loss 0.4803 | Train Sat 0.523 | Test Sat 0.514 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 600 | loss 0.4865 | Train Sat 0.524 | Test Sat 0.514 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 620 | loss 0.4820 | Train Sat 0.522 | Test Sat 0.515 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 640 | loss 0.4618 | Train Sat 0.525 | Test Sat 0.515 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 660 | loss 0.4658 | Train Sat 0.527 | Test Sat 0.516 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 680 | loss 0.4777 | Train Sat 0.525 | Test Sat 0.516 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 700 | loss 0.4914 | Train Sat 0.528 | Test Sat 0.517 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 720 | loss 0.4678 | Train Sat 0.530 | Test Sat 0.517 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 740 | loss 0.4711 | Train Sat 0.530 | Test Sat 0.518 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 760 | loss 0.4790 | Train Sat 0.528 | Test Sat 0.519 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 780 | loss 0.4773 | Train Sat 0.529 | Test Sat 0.519 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 800 | loss 0.4767 | Train Sat 0.529 | Test Sat 0.520 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 820 | loss 0.4422 | Train Sat 0.536 | Test Sat 0.520 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 840 | loss 0.4537 | Train Sat 0.532 | Test Sat 0.521 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 860 | loss 0.4839 | Train Sat 0.535 | Test Sat 0.521 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 880 | loss 0.4613 | Train Sat 0.532 | Test Sat 0.522 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 900 | loss 0.4299 | Train Sat 0.541 | Test Sat 0.522 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 920 | loss 0.4940 | Train Sat 0.536 | Test Sat 0.523 | Train Acc 0.889 | Test Acc 0.833\n",
            " epoch 940 | loss 0.4536 | Train Sat 0.539 | Test Sat 0.523 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 960 | loss 0.4582 | Train Sat 0.543 | Test Sat 0.524 | Train Acc 0.944 | Test Acc 0.833\n",
            " epoch 980 | loss 0.4520 | Train Sat 0.543 | Test Sat 0.525 | Train Acc 0.944 | Test Acc 0.833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_loader = DataLoader(X, y, 64, shuffle=False)\n",
        "for data, labels in all_loader:\n",
        "    predictions = east(data).detach().numpy()\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    print(predictions, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaRoqJ_OSlsH",
        "outputId": "151b843b-b1a6-42d0-871d-0d441adfdf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Letra B\n",
        "Execute o codigo LTNTorch para os 100 trens usando os mesmos\n",
        "procedimentos de treinamento da questão anterior."
      ],
      "metadata": {
        "id": "xbugcVqUKESN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
        "\n",
        "categorical_columns = ['shape', 'length', 'load_shape']\n",
        "numerical_columns = ['train_number', 'num_cars', 'num_loads', 'num_wheels', 'car_number', 'num_cars_loads']\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False, drop='first')\n",
        "encoded_categorical = encoder.fit_transform(transformed_df[categorical_columns])\n",
        "encoded_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_numerical = scaler.fit_transform(transformed_df[numerical_columns])\n",
        "scaled_df = pd.DataFrame(scaled_numerical, columns=numerical_columns)\n",
        "\n",
        "df_processed = pd.concat([transformed_df.drop(columns=categorical_columns + numerical_columns), scaled_df, encoded_df], axis=1)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_processed['direction'] = label_encoder.fit_transform(df_processed['direction'])\n",
        "\n",
        "X = df_processed.drop(columns=['direction'])\n",
        "y = df_processed['direction']\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "train_idx, test_idx = next(gss.split(X, y, groups=transformed_df['train_number']))\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "train_loader = DataLoader(X_train, y_train, 64, shuffle=True)\n",
        "test_loader = DataLoader(X_test, y_test, 64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTTgKbzINOHa",
        "outputId": "3cfca153-baf6-45d7-adbb-e183ee0e96cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_map = {\n",
        "    \"num_cars\": MLP(layer_sizes=(2, 8, 8, 2)),\n",
        "    \"num_loads\": MLP(layer_sizes=(2, 8, 8, 2)),\n",
        "    \"num_wheels\": MLP(layer_sizes=(3, 8, 8, 2)),\n",
        "    \"length\": MLP(layer_sizes=(4, 8, 8, 2)),\n",
        "    \"shape\": MLP(layer_sizes=(22, 16, 8, 2)),\n",
        "    \"num_cars_loads\": MLP(layer_sizes=(3, 8, 8, 2)),\n",
        "    \"load_shape\": MLP(layer_sizes=(12, 16, 8, 2)),\n",
        "    \"next_crc\": MLP(layer_sizes=(3, 8, 8, 2)),\n",
        "    \"next_hex\": MLP(layer_sizes=(3, 8, 8, 2)),\n",
        "    \"next_rec\": MLP(layer_sizes=(3, 8, 8, 2)),\n",
        "    \"next_tri\": MLP(layer_sizes=(3, 8, 8, 2))\n",
        "}\n",
        "indexer = {\n",
        "            \"num_cars\": list(range(0, 2)),\n",
        "            \"num_loads\": list(range(2, 4)),\n",
        "            \"num_wheels\": list(range(4, 7)),\n",
        "            \"length\": list(range(7, 11)),\n",
        "            \"shape\": list(range(11, 33)),\n",
        "            \"num_cars_loads\": list(range(33, 36)),\n",
        "            \"load_shape\": list(range(36, 48)),\n",
        "            \"next_crc\": list(range(48, 51)),\n",
        "            \"next_hex\": list(range(51, 54)),\n",
        "            \"next_rec\": list(range(54, 57)),\n",
        "            \"next_tri\": list(range(57, 60))\n",
        "        }\n",
        "east = EastModel(pred_map, indexer)\n",
        "P = ltn.Predicate(LogitsToPredicate(east))"
      ],
      "metadata": {
        "id": "XKoQtbd3QRJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_numbers_train = transformed_df.iloc[train_idx]['train_number'].unique()\n",
        "train_numbers_test = transformed_df.iloc[test_idx]['train_number'].unique()\n",
        "\n",
        "intersection = set(train_numbers_train).intersection(set(train_numbers_test))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.bar(train_numbers_train, [1] * len(train_numbers_train), color='blue', alpha=0.6, label='Train Set')\n",
        "plt.bar(train_numbers_test, [1] * len(train_numbers_test), color='red', alpha=0.6, label='Test Set')\n",
        "\n",
        "plt.xlabel('Train Number')\n",
        "plt.ylabel('Presence')\n",
        "plt.title('Train Numbers in Train and Test Sets')\n",
        "plt.legend()\n",
        "\n",
        "if intersection:\n",
        "    print(\"WARNING: The following train_numbers are in both subsets:\", intersection)\n",
        "    for train_number in intersection:\n",
        "        plt.bar(train_number, 1, color='green', alpha=1, label='Intersection')\n",
        "else:\n",
        "    print(\"No train_number appears in both train and test sets.\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "7KXSVMPNNTSm",
        "outputId": "550481eb-23b3-43f6-aaed-cc9aaddddfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No train_number appears in both train and test sets.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training\n",
        "optimizer = torch.optim.Adam(P.parameters(), lr=0.001)\n",
        "def compute_accuracy(loader):\n",
        "    mean_accuracy = 0.0\n",
        "    for data, labels in loader:\n",
        "        predictions = east(data).detach().numpy()\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        mean_accuracy += accuracy_score(labels, predictions)\n",
        "\n",
        "    return mean_accuracy / len(loader)\n",
        "\n",
        "for epoch in range(2000):\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x_W = ltn.Variable(\"x_W\", data[labels == 0]) # West samples\n",
        "        x_E = ltn.Variable(\"x_E\", data[labels == 1]) # East samples\n",
        "        sat_agg = SatAgg(\n",
        "            Forall(x_W, P(x_W, l_W, training=True)),\n",
        "            Forall(x_E, P(x_E, l_E, training=True)),\n",
        "        )\n",
        "        loss = 1. - sat_agg\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(\" epoch %d | loss %.4f | Train Sat %.3f | Test Sat %.3f | Train Acc %.3f | Test Acc %.3f\"\n",
        "              %(epoch, train_loss, compute_sat_level(train_loader), compute_sat_level(test_loader),\n",
        "                    compute_accuracy(train_loader), compute_accuracy(test_loader)))"
      ],
      "metadata": {
        "id": "5UxLSuh-KGj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9042a0ec-e044-4714-ff63-e9bcf85697ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch 0 | loss 0.5258 | Train Sat 0.480 | Test Sat 0.480 | Train Acc 0.500 | Test Acc 0.500\n",
            " epoch 20 | loss 0.5036 | Train Sat 0.502 | Test Sat 0.501 | Train Acc 0.512 | Test Acc 0.500\n",
            " epoch 40 | loss 0.5042 | Train Sat 0.503 | Test Sat 0.502 | Train Acc 0.688 | Test Acc 0.569\n",
            " epoch 60 | loss 0.4947 | Train Sat 0.505 | Test Sat 0.504 | Train Acc 0.696 | Test Acc 0.552\n",
            " epoch 80 | loss 0.4945 | Train Sat 0.507 | Test Sat 0.505 | Train Acc 0.710 | Test Acc 0.552\n",
            " epoch 100 | loss 0.4995 | Train Sat 0.508 | Test Sat 0.506 | Train Acc 0.600 | Test Acc 0.517\n",
            " epoch 120 | loss 0.4997 | Train Sat 0.509 | Test Sat 0.507 | Train Acc 0.576 | Test Acc 0.517\n",
            " epoch 140 | loss 0.5013 | Train Sat 0.511 | Test Sat 0.508 | Train Acc 0.604 | Test Acc 0.517\n",
            " epoch 160 | loss 0.4932 | Train Sat 0.511 | Test Sat 0.508 | Train Acc 0.606 | Test Acc 0.517\n",
            " epoch 180 | loss 0.5081 | Train Sat 0.511 | Test Sat 0.509 | Train Acc 0.604 | Test Acc 0.534\n",
            " epoch 200 | loss 0.4914 | Train Sat 0.512 | Test Sat 0.508 | Train Acc 0.629 | Test Acc 0.517\n",
            " epoch 220 | loss 0.5005 | Train Sat 0.512 | Test Sat 0.508 | Train Acc 0.631 | Test Acc 0.534\n",
            " epoch 240 | loss 0.4955 | Train Sat 0.512 | Test Sat 0.509 | Train Acc 0.596 | Test Acc 0.534\n",
            " epoch 260 | loss 0.4958 | Train Sat 0.513 | Test Sat 0.509 | Train Acc 0.594 | Test Acc 0.534\n",
            " epoch 280 | loss 0.4894 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.606 | Test Acc 0.534\n",
            " epoch 300 | loss 0.4898 | Train Sat 0.513 | Test Sat 0.509 | Train Acc 0.625 | Test Acc 0.534\n",
            " epoch 320 | loss 0.4926 | Train Sat 0.513 | Test Sat 0.509 | Train Acc 0.642 | Test Acc 0.569\n",
            " epoch 340 | loss 0.4960 | Train Sat 0.512 | Test Sat 0.509 | Train Acc 0.625 | Test Acc 0.552\n",
            " epoch 360 | loss 0.4869 | Train Sat 0.514 | Test Sat 0.509 | Train Acc 0.598 | Test Acc 0.534\n",
            " epoch 380 | loss 0.4878 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.639 | Test Acc 0.569\n",
            " epoch 400 | loss 0.4992 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.586 | Test Acc 0.534\n",
            " epoch 420 | loss 0.4961 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.594 | Test Acc 0.517\n",
            " epoch 440 | loss 0.4890 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.661 | Test Acc 0.552\n",
            " epoch 460 | loss 0.5011 | Train Sat 0.514 | Test Sat 0.511 | Train Acc 0.612 | Test Acc 0.534\n",
            " epoch 480 | loss 0.4969 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.649 | Test Acc 0.552\n",
            " epoch 500 | loss 0.4909 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.610 | Test Acc 0.534\n",
            " epoch 520 | loss 0.4912 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.631 | Test Acc 0.552\n",
            " epoch 540 | loss 0.4957 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.629 | Test Acc 0.517\n",
            " epoch 560 | loss 0.4913 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.616 | Test Acc 0.517\n",
            " epoch 580 | loss 0.4859 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.606 | Test Acc 0.517\n",
            " epoch 600 | loss 0.5010 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.630 | Test Acc 0.517\n",
            " epoch 620 | loss 0.4911 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.641 | Test Acc 0.534\n",
            " epoch 640 | loss 0.4930 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.637 | Test Acc 0.534\n",
            " epoch 660 | loss 0.4954 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.588 | Test Acc 0.517\n",
            " epoch 680 | loss 0.4930 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.600 | Test Acc 0.517\n",
            " epoch 700 | loss 0.4961 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.622 | Test Acc 0.517\n",
            " epoch 720 | loss 0.4914 | Train Sat 0.513 | Test Sat 0.509 | Train Acc 0.637 | Test Acc 0.517\n",
            " epoch 740 | loss 0.4888 | Train Sat 0.511 | Test Sat 0.509 | Train Acc 0.624 | Test Acc 0.517\n",
            " epoch 760 | loss 0.5023 | Train Sat 0.512 | Test Sat 0.509 | Train Acc 0.602 | Test Acc 0.517\n",
            " epoch 780 | loss 0.4953 | Train Sat 0.513 | Test Sat 0.509 | Train Acc 0.631 | Test Acc 0.534\n",
            " epoch 800 | loss 0.4850 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.606 | Test Acc 0.534\n",
            " epoch 820 | loss 0.4983 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.590 | Test Acc 0.534\n",
            " epoch 840 | loss 0.4908 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.592 | Test Acc 0.517\n",
            " epoch 860 | loss 0.4936 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.576 | Test Acc 0.517\n",
            " epoch 880 | loss 0.4954 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.614 | Test Acc 0.517\n",
            " epoch 900 | loss 0.4970 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.655 | Test Acc 0.569\n",
            " epoch 920 | loss 0.4958 | Train Sat 0.514 | Test Sat 0.509 | Train Acc 0.657 | Test Acc 0.552\n",
            " epoch 940 | loss 0.4857 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.632 | Test Acc 0.534\n",
            " epoch 960 | loss 0.4903 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.592 | Test Acc 0.517\n",
            " epoch 980 | loss 0.4985 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.635 | Test Acc 0.534\n",
            " epoch 1000 | loss 0.4970 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.641 | Test Acc 0.534\n",
            " epoch 1020 | loss 0.4903 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.633 | Test Acc 0.534\n",
            " epoch 1040 | loss 0.4932 | Train Sat 0.513 | Test Sat 0.509 | Train Acc 0.645 | Test Acc 0.552\n",
            " epoch 1060 | loss 0.4854 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.635 | Test Acc 0.534\n",
            " epoch 1080 | loss 0.4946 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.653 | Test Acc 0.534\n",
            " epoch 1100 | loss 0.4847 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.635 | Test Acc 0.534\n",
            " epoch 1120 | loss 0.4960 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.665 | Test Acc 0.552\n",
            " epoch 1140 | loss 0.4904 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.606 | Test Acc 0.517\n",
            " epoch 1160 | loss 0.4890 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.632 | Test Acc 0.517\n",
            " epoch 1180 | loss 0.4932 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.604 | Test Acc 0.534\n",
            " epoch 1200 | loss 0.4983 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.629 | Test Acc 0.517\n",
            " epoch 1220 | loss 0.4886 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.592 | Test Acc 0.517\n",
            " epoch 1240 | loss 0.4914 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.641 | Test Acc 0.517\n",
            " epoch 1260 | loss 0.4942 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.637 | Test Acc 0.517\n",
            " epoch 1280 | loss 0.4961 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.608 | Test Acc 0.517\n",
            " epoch 1300 | loss 0.4950 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.588 | Test Acc 0.534\n",
            " epoch 1320 | loss 0.4949 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.647 | Test Acc 0.517\n",
            " epoch 1340 | loss 0.4976 | Train Sat 0.514 | Test Sat 0.509 | Train Acc 0.614 | Test Acc 0.517\n",
            " epoch 1360 | loss 0.4923 | Train Sat 0.516 | Test Sat 0.510 | Train Acc 0.632 | Test Acc 0.534\n",
            " epoch 1380 | loss 0.4967 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.590 | Test Acc 0.517\n",
            " epoch 1400 | loss 0.4939 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.636 | Test Acc 0.517\n",
            " epoch 1420 | loss 0.4907 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.598 | Test Acc 0.517\n",
            " epoch 1440 | loss 0.5020 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.631 | Test Acc 0.517\n",
            " epoch 1460 | loss 0.4899 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.621 | Test Acc 0.517\n",
            " epoch 1480 | loss 0.4854 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.637 | Test Acc 0.534\n",
            " epoch 1500 | loss 0.4923 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.608 | Test Acc 0.517\n",
            " epoch 1520 | loss 0.4847 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.628 | Test Acc 0.517\n",
            " epoch 1540 | loss 0.4929 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.614 | Test Acc 0.517\n",
            " epoch 1560 | loss 0.4933 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.600 | Test Acc 0.534\n",
            " epoch 1580 | loss 0.4930 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.641 | Test Acc 0.552\n",
            " epoch 1600 | loss 0.4835 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.643 | Test Acc 0.569\n",
            " epoch 1620 | loss 0.4961 | Train Sat 0.514 | Test Sat 0.511 | Train Acc 0.608 | Test Acc 0.534\n",
            " epoch 1640 | loss 0.4854 | Train Sat 0.515 | Test Sat 0.510 | Train Acc 0.608 | Test Acc 0.517\n",
            " epoch 1660 | loss 0.4918 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.618 | Test Acc 0.534\n",
            " epoch 1680 | loss 0.4989 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.634 | Test Acc 0.517\n",
            " epoch 1700 | loss 0.4865 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.653 | Test Acc 0.517\n",
            " epoch 1720 | loss 0.4987 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.616 | Test Acc 0.534\n",
            " epoch 1740 | loss 0.4954 | Train Sat 0.516 | Test Sat 0.511 | Train Acc 0.608 | Test Acc 0.517\n",
            " epoch 1760 | loss 0.4997 | Train Sat 0.516 | Test Sat 0.511 | Train Acc 0.608 | Test Acc 0.534\n",
            " epoch 1780 | loss 0.4891 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.602 | Test Acc 0.534\n",
            " epoch 1800 | loss 0.4881 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.612 | Test Acc 0.517\n",
            " epoch 1820 | loss 0.4877 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.624 | Test Acc 0.517\n",
            " epoch 1840 | loss 0.5015 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.635 | Test Acc 0.552\n",
            " epoch 1860 | loss 0.4979 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.632 | Test Acc 0.534\n",
            " epoch 1880 | loss 0.4907 | Train Sat 0.513 | Test Sat 0.510 | Train Acc 0.617 | Test Acc 0.552\n",
            " epoch 1900 | loss 0.4923 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.632 | Test Acc 0.552\n",
            " epoch 1920 | loss 0.4856 | Train Sat 0.514 | Test Sat 0.511 | Train Acc 0.626 | Test Acc 0.534\n",
            " epoch 1940 | loss 0.4839 | Train Sat 0.515 | Test Sat 0.511 | Train Acc 0.640 | Test Acc 0.534\n",
            " epoch 1960 | loss 0.5005 | Train Sat 0.514 | Test Sat 0.510 | Train Acc 0.643 | Test Acc 0.552\n",
            " epoch 1980 | loss 0.4900 | Train Sat 0.514 | Test Sat 0.509 | Train Acc 0.625 | Test Acc 0.552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_loader = DataLoader(X, y, 64, shuffle=False)\n",
        "compute_accuracy(all_loader)\n",
        "for data, labels in all_loader:\n",
        "    predictions = east(data).detach().numpy()\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    print(predictions, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zACDKJkAL2Py",
        "outputId": "b38a99ba-f713-48cb-b88b-e6f0e71ac1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "[1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "[0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1] tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZZVfdTwTeEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}